{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OgxNuuqnPQHY"
      },
      "outputs": [],
      "source": [
        "# Step 1: Mount Drive manually\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Load setup function\n",
        "import sys\n",
        "sys.path.append('/content/drive/MyDrive/colab_utils')\n",
        "\n",
        "from colab_setup import setup_colab_caching\n",
        "setup_colab_caching()"
      ],
      "metadata": {
        "id": "5HIHC9h-PXkH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fvWMgR-1EAp"
      },
      "outputs": [],
      "source": [
        "!pip install -q --upgrade torch==2.5.1+cu124 torchvision==0.20.1+cu124 --index-url https://download.pytorch.org/whl/cu124\n",
        "!pip install -q --upgrade mlx_lm datasets==3.2.0 diffusers\n",
        "!pip install -q transformers==4.48.3 requests bitsandbytes==0.46.0 accelerate==1.3.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_lT__q9f1J4r"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "import torch\n",
        "from IPython.display import Markdown, display, update_display\n",
        "from google.colab import userdata\n",
        "from huggingface_hub import login\n",
        "from google.colab import drive\n",
        "from transformers import AutoTokenizer, AutoModelForCausalLM, TextStreamer, BitsAndBytesConfig\n",
        "import gradio as gr"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "euV6a-WK1LsS"
      },
      "outputs": [],
      "source": [
        "# Constants\n",
        "\n",
        "LLAMA = \"meta-llama/Llama-3.2-3B-Instruct\"\n",
        "QWEN = \"Qwen/Qwen2.5-7B-Instruct\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-d2jWHNg1VRb"
      },
      "outputs": [],
      "source": [
        "# New capability - connect this Colab to my Google Drive\n",
        "# See immediately below this for instructions to obtain denver_extract.mp3\n",
        "\n",
        "drive.mount(\"/content/drive\")\n",
        "data_filename = \"/content/drive/MyDrive/llms/reviews_dataset.txt\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jsohe59A1b6C"
      },
      "outputs": [],
      "source": [
        "# Sign in to HuggingFace Hub\n",
        "\n",
        "hf_token = userdata.get('HF_TOKEN')\n",
        "login(hf_token, add_to_git_credential=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gqkw7Z5p1f-R"
      },
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a synthetic dataset generator. You will be provided with a description of the type of data to generate, along with a JSON example of one or more data rows, and a number of rows to generate.\n",
        "Your job is to generate a number of rows, according to the number of rows provided to you.\n",
        "\n",
        "Return only JSON rows and nothing else.\n",
        "\n",
        "Here is an example of what a user might ask:\n",
        "\n",
        "Data description:\n",
        "Generate an imaginary coffee shop in the Vietnamese city of Danang.\n",
        "The coffee shop should have a new name, a star rating, and 3 customer reviews, and location as an address.\n",
        "The star rating should be random from 1 to 5.\n",
        "The customer reviews should be reflecting positive or negative experiences.\n",
        "\n",
        "Example JSON row:\n",
        "{\"name\" : \"Phuong's beach cafe\", \"star_rating\": 4, \"customer_reviews\": [\"Great place by the beach!\", \"I had a cockroach inside my smoothie!\", \"It was raining but I still had fun there near the beach.\"], \"location\": \"01 An Thuong 30, My An ward, Ngu Hanh Son district\"}\n",
        "{\"name\" : \"The coffee factory\", \"star_rating\": 1, \"customer_reviews\": [\"It's a hellish place\", \"I had food poisoning!\", \"The staff were so rude!\"], \"location\": \"22 Nguyen Giap, An Hai ward, Son Tra district\"}\n",
        "\n",
        "Number of rows:\n",
        "3\n",
        "\n",
        "For this request, the generated result could be like:\n",
        "{\"name\" : \"Vietnamese Dream\", \"star_rating\": 4, \"customer_reviews\": [\"The coffee is amazing and so is the view!\", \"I loved the traditional Vietnamese desserts they offer!\", \"The service was fantastic and the ambiance was perfect for a date.\"], \"location\": \"36 Ho Xuan Huong, Thanh Khe ward, Thanh Khe district\"}\n",
        "{\"name\" : \"Nam Viet Brews\", \"star_rating\": 5, \"customer_reviews\": [\"The best coffee in Danang!\", \"Amazing atmosphere with live music on weekends!\", \"Staff is super friendly and accommodating.\"], \"location\": \"34 Tran Phu street, Thanh Khe ward, Thanh Khe district\"}\n",
        "{\"name\" : \"Danang View Espresso\", \"star_rating\": 4, \"customer_reviews\": [\"The view is breathtaking and the coffee is delicious!\", \"Service was amazing, really friendly staff!\", \"Had a great time here with friends, highly recommend!\"], \"location\": \"45 Nguyen Hue Avenue, Thanh Kiem ward, Hoa Khanh district\"}\n",
        "\n",
        "If the data description is not clear, respond only with:\n",
        "The data description is not clear\n",
        "\n",
        "If the example JSON row is not JSON or contains anything other than JSON, or is a malformed JSON, respond with:\n",
        "The example JSON row is not JSON\n",
        "\n",
        "If the number of rows is not a number, respond with:\n",
        "The number of rows is not a number\n",
        "\"\"\"\n",
        "\n",
        "def get_messages(description, json_example, number):\n",
        "  return [\n",
        "      {\"role\": \"system\", \"content\": system_prompt},\n",
        "      {\"role\": \"user\", \"content\": f\"\"\"\n",
        "Data description:\n",
        "{description}\n",
        "\n",
        "Example JSON row:\n",
        "{json_example}\n",
        "\n",
        "Number of rows:\n",
        "{number}\n",
        "\"\"\"}]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "qwen_quant_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_compute_dtype=torch.bfloat16,\n",
        "    bnb_4bit_quant_type=\"nf4\"\n",
        ")\n",
        "\n",
        "qwen_model = AutoModelForCausalLM.from_pretrained(\n",
        "    QWEN,\n",
        "    torch_dtype=\"auto\",\n",
        "    device_map=\"auto\",\n",
        "    quantization_config=qwen_quant_config\n",
        ")\n",
        "qwen_tokenizer = AutoTokenizer.from_pretrained(QWEN)\n",
        "\n",
        "def generate_qwen(messages):\n",
        "  text = qwen_tokenizer.apply_chat_template(\n",
        "      messages,\n",
        "      tokenize=False,\n",
        "      add_generation_prompt=True\n",
        "  )\n",
        "  model_inputs = qwen_tokenizer([text], return_tensors=\"pt\").to(qwen_model.device)\n",
        "\n",
        "  generated_ids = qwen_model.generate(\n",
        "      **model_inputs,\n",
        "      max_new_tokens=2048\n",
        "  )\n",
        "  generated_ids = [\n",
        "      output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)\n",
        "  ]\n",
        "\n",
        "  response = qwen_tokenizer.batch_decode(generated_ids, skip_special_tokens=True)[0]\n",
        "  return response"
      ],
      "metadata": {
        "id": "nJQM9Q5oOroo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(data_filename, \"a\") as file:\n",
        "  for i in range(10):\n",
        "    generated = generate_qwen()\n",
        "    file.write(generated + \"\\n\")"
      ],
      "metadata": {
        "id": "wNXihSOrIkqD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(generate_qwen())"
      ],
      "metadata": {
        "id": "ahyKjHyfSD4N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset(description, json_example, number):\n",
        "  messages = get_messages(description, json_example, number)\n",
        "  response = generate_qwen(messages)\n",
        "  with open(data_filename, \"a\") as file:\n",
        "    file.write(response)\n",
        "  return response"
      ],
      "metadata": {
        "id": "3gRcJwYNRjib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradio stuff\n",
        "view = gr.Interface(\n",
        "    fn=create_dataset,\n",
        "    inputs=[gr.Textbox(label=\"Your dataset description:\"), gr.Textbox(label=\"Your example JSON rows:\"), gr.Textbox(label=\"number of rows to generate:\")],\n",
        "    outputs=[gr.Markdown(label=\"Response:\")],\n",
        "    flagging_mode=\"never\"\n",
        ")\n",
        "view.launch()"
      ],
      "metadata": {
        "id": "hek_gzL-RaOV"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}